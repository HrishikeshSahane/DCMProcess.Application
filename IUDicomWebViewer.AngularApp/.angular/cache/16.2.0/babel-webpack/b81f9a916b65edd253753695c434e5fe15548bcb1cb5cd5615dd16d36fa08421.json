{"ast":null,"code":"var Utils = require(\"./util\"),\n  Headers = require(\"./headers\"),\n  Constants = Utils.Constants,\n  Methods = require(\"./methods\");\nmodule.exports = function ( /*Buffer*/input) {\n  var _entryHeader = new Headers.EntryHeader(),\n    _entryName = Buffer.alloc(0),\n    _comment = Buffer.alloc(0),\n    _isDirectory = false,\n    uncompressedData = null,\n    _extra = Buffer.alloc(0);\n  function getCompressedDataFromZip() {\n    if (!input || !Buffer.isBuffer(input)) {\n      return Buffer.alloc(0);\n    }\n    _entryHeader.loadDataHeaderFromBinary(input);\n    return input.slice(_entryHeader.realDataOffset, _entryHeader.realDataOffset + _entryHeader.compressedSize);\n  }\n  function crc32OK(data) {\n    // if bit 3 (0x08) of the general-purpose flags field is set, then the CRC-32 and file sizes are not known when the header is written\n    if ((_entryHeader.flags & 0x8) !== 0x8) {\n      if (Utils.crc32(data) !== _entryHeader.dataHeader.crc) {\n        return false;\n      }\n    } else {\n      // @TODO: load and check data descriptor header\n      // The fields in the local header are filled with zero, and the CRC-32 and size are appended in a 12-byte structure\n      // (optionally preceded by a 4-byte signature) immediately after the compressed data:\n    }\n    return true;\n  }\n  function decompress( /*Boolean*/async, /*Function*/callback, /*String, Buffer*/pass) {\n    if (typeof callback === \"undefined\" && typeof async === \"string\") {\n      pass = async;\n      async = void 0;\n    }\n    if (_isDirectory) {\n      if (async && callback) {\n        callback(Buffer.alloc(0), Utils.Errors.DIRECTORY_CONTENT_ERROR); //si added error.\n      }\n\n      return Buffer.alloc(0);\n    }\n    var compressedData = getCompressedDataFromZip();\n    if (compressedData.length === 0) {\n      // File is empty, nothing to decompress.\n      if (async && callback) callback(compressedData);\n      return compressedData;\n    }\n    if (_entryHeader.encripted) {\n      if (\"string\" !== typeof pass && !Buffer.isBuffer(pass)) {\n        throw new Error(\"ADM-ZIP: Incompatible password parameter\");\n      }\n      compressedData = Methods.ZipCrypto.decrypt(compressedData, _entryHeader, pass);\n    }\n    var data = Buffer.alloc(_entryHeader.size);\n    switch (_entryHeader.method) {\n      case Utils.Constants.STORED:\n        compressedData.copy(data);\n        if (!crc32OK(data)) {\n          if (async && callback) callback(data, Utils.Errors.BAD_CRC); //si added error\n          throw new Error(Utils.Errors.BAD_CRC);\n        } else {\n          //si added otherwise did not seem to return data.\n          if (async && callback) callback(data);\n          return data;\n        }\n      case Utils.Constants.DEFLATED:\n        var inflater = new Methods.Inflater(compressedData);\n        if (!async) {\n          const result = inflater.inflate(data);\n          result.copy(data, 0);\n          if (!crc32OK(data)) {\n            throw new Error(Utils.Errors.BAD_CRC + \" \" + _entryName.toString());\n          }\n          return data;\n        } else {\n          inflater.inflateAsync(function (result) {\n            result.copy(result, 0);\n            if (callback) {\n              if (!crc32OK(result)) {\n                callback(result, Utils.Errors.BAD_CRC); //si added error\n              } else {\n                callback(result);\n              }\n            }\n          });\n        }\n        break;\n      default:\n        if (async && callback) callback(Buffer.alloc(0), Utils.Errors.UNKNOWN_METHOD);\n        throw new Error(Utils.Errors.UNKNOWN_METHOD);\n    }\n  }\n  function compress( /*Boolean*/async, /*Function*/callback) {\n    if ((!uncompressedData || !uncompressedData.length) && Buffer.isBuffer(input)) {\n      // no data set or the data wasn't changed to require recompression\n      if (async && callback) callback(getCompressedDataFromZip());\n      return getCompressedDataFromZip();\n    }\n    if (uncompressedData.length && !_isDirectory) {\n      var compressedData;\n      // Local file header\n      switch (_entryHeader.method) {\n        case Utils.Constants.STORED:\n          _entryHeader.compressedSize = _entryHeader.size;\n          compressedData = Buffer.alloc(uncompressedData.length);\n          uncompressedData.copy(compressedData);\n          if (async && callback) callback(compressedData);\n          return compressedData;\n        default:\n        case Utils.Constants.DEFLATED:\n          var deflater = new Methods.Deflater(uncompressedData);\n          if (!async) {\n            var deflated = deflater.deflate();\n            _entryHeader.compressedSize = deflated.length;\n            return deflated;\n          } else {\n            deflater.deflateAsync(function (data) {\n              compressedData = Buffer.alloc(data.length);\n              _entryHeader.compressedSize = data.length;\n              data.copy(compressedData);\n              callback && callback(compressedData);\n            });\n          }\n          deflater = null;\n          break;\n      }\n    } else if (async && callback) {\n      callback(Buffer.alloc(0));\n    } else {\n      return Buffer.alloc(0);\n    }\n  }\n  function readUInt64LE(buffer, offset) {\n    return (buffer.readUInt32LE(offset + 4) << 4) + buffer.readUInt32LE(offset);\n  }\n  function parseExtra(data) {\n    var offset = 0;\n    var signature, size, part;\n    while (offset < data.length) {\n      signature = data.readUInt16LE(offset);\n      offset += 2;\n      size = data.readUInt16LE(offset);\n      offset += 2;\n      part = data.slice(offset, offset + size);\n      offset += size;\n      if (Constants.ID_ZIP64 === signature) {\n        parseZip64ExtendedInformation(part);\n      }\n    }\n  }\n\n  //Override header field values with values from the ZIP64 extra field\n  function parseZip64ExtendedInformation(data) {\n    var size, compressedSize, offset, diskNumStart;\n    if (data.length >= Constants.EF_ZIP64_SCOMP) {\n      size = readUInt64LE(data, Constants.EF_ZIP64_SUNCOMP);\n      if (_entryHeader.size === Constants.EF_ZIP64_OR_32) {\n        _entryHeader.size = size;\n      }\n    }\n    if (data.length >= Constants.EF_ZIP64_RHO) {\n      compressedSize = readUInt64LE(data, Constants.EF_ZIP64_SCOMP);\n      if (_entryHeader.compressedSize === Constants.EF_ZIP64_OR_32) {\n        _entryHeader.compressedSize = compressedSize;\n      }\n    }\n    if (data.length >= Constants.EF_ZIP64_DSN) {\n      offset = readUInt64LE(data, Constants.EF_ZIP64_RHO);\n      if (_entryHeader.offset === Constants.EF_ZIP64_OR_32) {\n        _entryHeader.offset = offset;\n      }\n    }\n    if (data.length >= Constants.EF_ZIP64_DSN + 4) {\n      diskNumStart = data.readUInt32LE(Constants.EF_ZIP64_DSN);\n      if (_entryHeader.diskNumStart === Constants.EF_ZIP64_OR_16) {\n        _entryHeader.diskNumStart = diskNumStart;\n      }\n    }\n  }\n  return {\n    get entryName() {\n      return _entryName.toString();\n    },\n    get rawEntryName() {\n      return _entryName;\n    },\n    set entryName(val) {\n      _entryName = Utils.toBuffer(val);\n      var lastChar = _entryName[_entryName.length - 1];\n      _isDirectory = lastChar === 47 || lastChar === 92;\n      _entryHeader.fileNameLength = _entryName.length;\n    },\n    get extra() {\n      return _extra;\n    },\n    set extra(val) {\n      _extra = val;\n      _entryHeader.extraLength = val.length;\n      parseExtra(val);\n    },\n    get comment() {\n      return _comment.toString();\n    },\n    set comment(val) {\n      _comment = Utils.toBuffer(val);\n      _entryHeader.commentLength = _comment.length;\n    },\n    get name() {\n      var n = _entryName.toString();\n      return _isDirectory ? n.substr(n.length - 1).split(\"/\").pop() : n.split(\"/\").pop();\n    },\n    get isDirectory() {\n      return _isDirectory;\n    },\n    getCompressedData: function () {\n      return compress(false, null);\n    },\n    getCompressedDataAsync: function ( /*Function*/callback) {\n      compress(true, callback);\n    },\n    setData: function (value) {\n      uncompressedData = Utils.toBuffer(value);\n      if (!_isDirectory && uncompressedData.length) {\n        _entryHeader.size = uncompressedData.length;\n        _entryHeader.method = Utils.Constants.DEFLATED;\n        _entryHeader.crc = Utils.crc32(value);\n        _entryHeader.changed = true;\n      } else {\n        // folders and blank files should be stored\n        _entryHeader.method = Utils.Constants.STORED;\n      }\n    },\n    getData: function (pass) {\n      if (_entryHeader.changed) {\n        return uncompressedData;\n      } else {\n        return decompress(false, null, pass);\n      }\n    },\n    getDataAsync: function ( /*Function*/callback, pass) {\n      if (_entryHeader.changed) {\n        callback(uncompressedData);\n      } else {\n        decompress(true, callback, pass);\n      }\n    },\n    set attr(attr) {\n      _entryHeader.attr = attr;\n    },\n    get attr() {\n      return _entryHeader.attr;\n    },\n    set header( /*Buffer*/data) {\n      _entryHeader.loadFromBinary(data);\n    },\n    get header() {\n      return _entryHeader;\n    },\n    packHeader: function () {\n      // 1. create header (buffer)\n      var header = _entryHeader.entryHeaderToBinary();\n      var addpos = Utils.Constants.CENHDR;\n      // 2. add file name\n      _entryName.copy(header, addpos);\n      addpos += _entryName.length;\n      // 3. add extra data\n      if (_entryHeader.extraLength) {\n        _extra.copy(header, addpos);\n        addpos += _entryHeader.extraLength;\n      }\n      // 4. add file comment\n      if (_entryHeader.commentLength) {\n        _comment.copy(header, addpos);\n      }\n      return header;\n    },\n    toJSON: function () {\n      const bytes = function (nr) {\n        return \"<\" + (nr && nr.length + \" bytes buffer\" || \"null\") + \">\";\n      };\n      return {\n        entryName: this.entryName,\n        name: this.name,\n        comment: this.comment,\n        isDirectory: this.isDirectory,\n        header: _entryHeader.toJSON(),\n        compressedData: bytes(input),\n        data: bytes(uncompressedData)\n      };\n    },\n    toString: function () {\n      return JSON.stringify(this.toJSON(), null, \"\\t\");\n    }\n  };\n};","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}