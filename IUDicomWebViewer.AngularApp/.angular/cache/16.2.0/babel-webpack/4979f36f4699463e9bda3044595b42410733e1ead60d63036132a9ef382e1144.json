{"ast":null,"code":"const ZipEntry = require(\"./zipEntry\");\nconst Headers = require(\"./headers\");\nconst Utils = require(\"./util\");\nmodule.exports = function ( /*Buffer|null*/inBuffer, /** object */options) {\n  var entryList = [],\n    entryTable = {},\n    _comment = Buffer.alloc(0),\n    mainHeader = new Headers.MainHeader(),\n    loadedEntries = false;\n\n  // assign options\n  const opts = Object.assign(Object.create(null), options);\n  const {\n    noSort\n  } = opts;\n  if (inBuffer) {\n    // is a memory buffer\n    readMainHeader(opts.readEntries);\n  } else {\n    // none. is a new file\n    loadedEntries = true;\n  }\n  function iterateEntries(callback) {\n    const totalEntries = mainHeader.diskEntries; // total number of entries\n    let index = mainHeader.offset; // offset of first CEN header\n\n    for (let i = 0; i < totalEntries; i++) {\n      let tmp = index;\n      const entry = new ZipEntry(inBuffer);\n      entry.header = inBuffer.slice(tmp, tmp += Utils.Constants.CENHDR);\n      entry.entryName = inBuffer.slice(tmp, tmp += entry.header.fileNameLength);\n      index += entry.header.entryHeaderSize;\n      callback(entry);\n    }\n  }\n  function readEntries() {\n    loadedEntries = true;\n    entryTable = {};\n    entryList = new Array(mainHeader.diskEntries); // total number of entries\n    var index = mainHeader.offset; // offset of first CEN header\n    for (var i = 0; i < entryList.length; i++) {\n      var tmp = index,\n        entry = new ZipEntry(inBuffer);\n      entry.header = inBuffer.slice(tmp, tmp += Utils.Constants.CENHDR);\n      entry.entryName = inBuffer.slice(tmp, tmp += entry.header.fileNameLength);\n      if (entry.header.extraLength) {\n        entry.extra = inBuffer.slice(tmp, tmp += entry.header.extraLength);\n      }\n      if (entry.header.commentLength) entry.comment = inBuffer.slice(tmp, tmp + entry.header.commentLength);\n      index += entry.header.entryHeaderSize;\n      entryList[i] = entry;\n      entryTable[entry.entryName] = entry;\n    }\n  }\n  function readMainHeader( /*Boolean*/readNow) {\n    var i = inBuffer.length - Utils.Constants.ENDHDR,\n      // END header size\n      max = Math.max(0, i - 0xffff),\n      // 0xFFFF is the max zip file comment length\n      n = max,\n      endStart = inBuffer.length,\n      endOffset = -1,\n      // Start offset of the END header\n      commentEnd = 0;\n    for (i; i >= n; i--) {\n      if (inBuffer[i] !== 0x50) continue; // quick check that the byte is 'P'\n      if (inBuffer.readUInt32LE(i) === Utils.Constants.ENDSIG) {\n        // \"PK\\005\\006\"\n        endOffset = i;\n        commentEnd = i;\n        endStart = i + Utils.Constants.ENDHDR;\n        // We already found a regular signature, let's look just a bit further to check if there's any zip64 signature\n        n = i - Utils.Constants.END64HDR;\n        continue;\n      }\n      if (inBuffer.readUInt32LE(i) === Utils.Constants.END64SIG) {\n        // Found a zip64 signature, let's continue reading the whole zip64 record\n        n = max;\n        continue;\n      }\n      if (inBuffer.readUInt32LE(i) === Utils.Constants.ZIP64SIG) {\n        // Found the zip64 record, let's determine it's size\n        endOffset = i;\n        endStart = i + Utils.readBigUInt64LE(inBuffer, i + Utils.Constants.ZIP64SIZE) + Utils.Constants.ZIP64LEAD;\n        break;\n      }\n    }\n    if (!~endOffset) throw new Error(Utils.Errors.INVALID_FORMAT);\n    mainHeader.loadFromBinary(inBuffer.slice(endOffset, endStart));\n    if (mainHeader.commentLength) {\n      _comment = inBuffer.slice(commentEnd + Utils.Constants.ENDHDR);\n    }\n    if (readNow) readEntries();\n  }\n  function sortEntries() {\n    if (entryList.length > 1 && !noSort) {\n      entryList.sort((a, b) => a.entryName.toLowerCase().localeCompare(b.entryName.toLowerCase()));\n    }\n  }\n  return {\n    /**\n     * Returns an array of ZipEntry objects existent in the current opened archive\n     * @return Array\n     */\n    get entries() {\n      if (!loadedEntries) {\n        readEntries();\n      }\n      return entryList;\n    },\n    /**\n     * Archive comment\n     * @return {String}\n     */\n    get comment() {\n      return _comment.toString();\n    },\n    set comment(val) {\n      _comment = Utils.toBuffer(val);\n      mainHeader.commentLength = _comment.length;\n    },\n    getEntryCount: function () {\n      if (!loadedEntries) {\n        return mainHeader.diskEntries;\n      }\n      return entryList.length;\n    },\n    forEach: function (callback) {\n      if (!loadedEntries) {\n        iterateEntries(callback);\n        return;\n      }\n      entryList.forEach(callback);\n    },\n    /**\n     * Returns a reference to the entry with the given name or null if entry is inexistent\n     *\n     * @param entryName\n     * @return ZipEntry\n     */\n    getEntry: function ( /*String*/entryName) {\n      if (!loadedEntries) {\n        readEntries();\n      }\n      return entryTable[entryName] || null;\n    },\n    /**\n     * Adds the given entry to the entry list\n     *\n     * @param entry\n     */\n    setEntry: function ( /*ZipEntry*/entry) {\n      if (!loadedEntries) {\n        readEntries();\n      }\n      entryList.push(entry);\n      entryTable[entry.entryName] = entry;\n      mainHeader.totalEntries = entryList.length;\n    },\n    /**\n     * Removes the entry with the given name from the entry list.\n     *\n     * If the entry is a directory, then all nested files and directories will be removed\n     * @param entryName\n     */\n    deleteEntry: function ( /*String*/entryName) {\n      if (!loadedEntries) {\n        readEntries();\n      }\n      var entry = entryTable[entryName];\n      if (entry && entry.isDirectory) {\n        var _self = this;\n        this.getEntryChildren(entry).forEach(function (child) {\n          if (child.entryName !== entryName) {\n            _self.deleteEntry(child.entryName);\n          }\n        });\n      }\n      entryList.splice(entryList.indexOf(entry), 1);\n      delete entryTable[entryName];\n      mainHeader.totalEntries = entryList.length;\n    },\n    /**\n     *  Iterates and returns all nested files and directories of the given entry\n     *\n     * @param entry\n     * @return Array\n     */\n    getEntryChildren: function ( /*ZipEntry*/entry) {\n      if (!loadedEntries) {\n        readEntries();\n      }\n      if (entry && entry.isDirectory) {\n        const list = [];\n        const name = entry.entryName;\n        const len = name.length;\n        entryList.forEach(function (zipEntry) {\n          if (zipEntry.entryName.substr(0, len) === name) {\n            list.push(zipEntry);\n          }\n        });\n        return list;\n      }\n      return [];\n    },\n    /**\n     * Returns the zip file\n     *\n     * @return Buffer\n     */\n    compressToBuffer: function () {\n      if (!loadedEntries) {\n        readEntries();\n      }\n      sortEntries();\n      const dataBlock = [];\n      const entryHeaders = [];\n      let totalSize = 0;\n      let dindex = 0;\n      mainHeader.size = 0;\n      mainHeader.offset = 0;\n      for (const entry of entryList) {\n        // compress data and set local and entry header accordingly. Reason why is called first\n        const compressedData = entry.getCompressedData();\n        // 1. construct data header\n        entry.header.offset = dindex;\n        const dataHeader = entry.header.dataHeaderToBinary();\n        const entryNameLen = entry.rawEntryName.length;\n        // 1.2. postheader - data after data header\n        const postHeader = Buffer.alloc(entryNameLen + entry.extra.length);\n        entry.rawEntryName.copy(postHeader, 0);\n        postHeader.copy(entry.extra, entryNameLen);\n\n        // 2. offsets\n        const dataLength = dataHeader.length + postHeader.length + compressedData.length;\n        dindex += dataLength;\n\n        // 3. store values in sequence\n        dataBlock.push(dataHeader);\n        dataBlock.push(postHeader);\n        dataBlock.push(compressedData);\n\n        // 4. construct entry header\n        const entryHeader = entry.packHeader();\n        entryHeaders.push(entryHeader);\n        // 5. update main header\n        mainHeader.size += entryHeader.length;\n        totalSize += dataLength + entryHeader.length;\n      }\n      totalSize += mainHeader.mainHeaderSize; // also includes zip file comment length\n      // point to end of data and beginning of central directory first record\n      mainHeader.offset = dindex;\n      dindex = 0;\n      const outBuffer = Buffer.alloc(totalSize);\n      // write data blocks\n      for (const content of dataBlock) {\n        content.copy(outBuffer, dindex);\n        dindex += content.length;\n      }\n\n      // write central directory entries\n      for (const content of entryHeaders) {\n        content.copy(outBuffer, dindex);\n        dindex += content.length;\n      }\n\n      // write main header\n      const mh = mainHeader.toBinary();\n      if (_comment) {\n        _comment.copy(mh, Utils.Constants.ENDHDR); // add zip file comment\n      }\n\n      mh.copy(outBuffer, dindex);\n      return outBuffer;\n    },\n    toAsyncBuffer: function ( /*Function*/onSuccess, /*Function*/onFail, /*Function*/onItemStart, /*Function*/onItemEnd) {\n      try {\n        if (!loadedEntries) {\n          readEntries();\n        }\n        sortEntries();\n        const dataBlock = [];\n        const entryHeaders = [];\n        let totalSize = 0;\n        let dindex = 0;\n        mainHeader.size = 0;\n        mainHeader.offset = 0;\n        const compress2Buffer = function (entryLists) {\n          if (entryLists.length) {\n            const entry = entryLists.pop();\n            const name = entry.entryName + entry.extra.toString();\n            if (onItemStart) onItemStart(name);\n            entry.getCompressedDataAsync(function (compressedData) {\n              if (onItemEnd) onItemEnd(name);\n              entry.header.offset = dindex;\n              // data header\n              const dataHeader = entry.header.dataHeaderToBinary();\n              const postHeader = Buffer.alloc(name.length, name);\n              const dataLength = dataHeader.length + postHeader.length + compressedData.length;\n              dindex += dataLength;\n              dataBlock.push(dataHeader);\n              dataBlock.push(postHeader);\n              dataBlock.push(compressedData);\n              const entryHeader = entry.packHeader();\n              entryHeaders.push(entryHeader);\n              mainHeader.size += entryHeader.length;\n              totalSize += dataLength + entryHeader.length;\n              compress2Buffer(entryLists);\n            });\n          } else {\n            totalSize += mainHeader.mainHeaderSize; // also includes zip file comment length\n            // point to end of data and beginning of central directory first record\n            mainHeader.offset = dindex;\n            dindex = 0;\n            const outBuffer = Buffer.alloc(totalSize);\n            dataBlock.forEach(function (content) {\n              content.copy(outBuffer, dindex); // write data blocks\n              dindex += content.length;\n            });\n            entryHeaders.forEach(function (content) {\n              content.copy(outBuffer, dindex); // write central directory entries\n              dindex += content.length;\n            });\n            const mh = mainHeader.toBinary();\n            if (_comment) {\n              _comment.copy(mh, Utils.Constants.ENDHDR); // add zip file comment\n            }\n\n            mh.copy(outBuffer, dindex); // write main header\n\n            onSuccess(outBuffer);\n          }\n        };\n        compress2Buffer(entryList);\n      } catch (e) {\n        onFail(e);\n      }\n    }\n  };\n};","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}